Setting the AI record straight (for now)

Artificial intelligence is changing at a breathtaking pace the way we interact with our devices, friends and data. It promises to revolutionize how we work, shop, socialize, date, bank, heal, navigate… how we live.

Yet here I am in the engine room of the revolution, getting increasingly frustrated with the prevalentAIconversations and memes. We’re painting a partial, bipolar, even misleading picture. “We” sometimes includes me, and it includes journalists, pundits, analysts and even practitioners.

What do I mean? Specifically, we highlight the highs (AlphaGo beats world champion!) and lambast the lows (Chatbot Tay turns racist and hateful!), while brushing off smaller (but meaningful) advances. We keep giving air time to robot-takeover fears, while failing to evangelize and thus guide the real value ofAItoday.

As humans, we’re drawn to the dramatic, but as an industry, we have a responsibility to get everyone on the same, grounded-in-reality page. So forgive me for sharpening my proverbial axe. Here are three specificAItopics that need a reboot.

We are all rightly in awe of the splashy, sexy and sometimes scaryAIconcepts we read about in the headlines.The end of apps,the end of screens,autonomous vehicles,autonomous weapon systems… Though not difficult to imagine, many of these scenarios are several years out. But less sensationalAImodels are already here,now, improving our everyday experiences. They’re great. And we should talk about them more.

A broad array of companies are quietly innovating on top ofAItechnologies — and integrating the resulting innovations into services today. Their models are showing us the right products (e.g.Expedia,Getty Images), serving smarter ads (e.g.GumGum,Pinterest), organizing our content (e.g.GoPro,Microsoft), guiding investments (e.g.Sentient), talking to us in the words we understand (e.g. DoCoMo,IBM Watson) and more. Each of these is one of our customers, and each of them is filled with smart people working hard to improve their products usingAI. Many of them work on agile software teams. Over time, their incremental progress will revolutionize technology. But don’t expect to wake up tomorrow as Bruce Willis in “Surrogates.”

In thisAISpring, we’re seeing big news almost daily, much of it brought to us by the tech behemoths we all know and love. Google, Amazon, Microsoft, IBM, Facebook, Apple and others are constantly making waves with newAIprojects and developments. And these companies arepaying big money forAIstartups(recent examples includeTuriandNervana). It’swar.

But AIs are not just for the big guys. Why? Three reasons. First, the affordability of massive computing power. Indeed, the commoditization of compute power is a large part of why the big cloud platforms want you developing models on top of Azure, AWS, Watson and GCP, and why Intel and NVIDIA want you doing it on their silicon. Second, there are more ML- andAI-trained engineersthan ever before, taking advantage of decades of science advancing the underlying algorithms.Third, largely behind the scenes, product teams from startups to retailers and systems integrators are applying others’AIplatforms using their own proprietary training data. The most sophisticated algorithms are only able to see, listen, talk and “think” like humans if the right humans are training and re-training them as our fickle human opinions evolve. Nobody understands shoes like Shoes.com, surfing videos like GoPro, top-shelf stock imagery like Getty — and their customers.Sometimes the ability to leverage cognitive computing is less about the underlying algorithms and more about how they are tuned and productized. Mark my words: It’s not just who has the models, it’s about who applies the right data.A means, not an endLastly, can we please stop evaluating AIs based on whether they are saving us from cancer or threatening humanity? These questions bait valuable conversations, but miss the bigger, more important “middle.” I love telling my mom that we train AIs. But AIs are not the goal. When we all go to that tech-loving part of our brain, we forget that AIs are themeansto improved experiences.We all accept that a picture is “worth a thousand words.” We also know that most of our communication is non-verbal (just contrast your last date, or in-person interview, with your last telecon call). So how much are 100 million images worth? How about terabytes of CT scans of your loved one’s brain tumor? And what about 24 hours of video, at 30 fps? Well, of course, that depends on what’s in the data — and, more importantly, what we can do with it.AIs hold the key to unlocking the value buried in the massive, exponentially growing sets of unstructured content with which we each interact daily.As such, I humbly propose that we measure the value of anAIbased on its ability to contribute positive utility to people. We all know that at the end of the day, it’s the people who matter in our lives. Just the same, we need to remember that AIs should be measured by their ability to understand, interact with and improve people’s lives. This utilitarian framework offers hundreds of years of insights from philosophers, economists and anthropologists.The new nukesAIs are pervasive, and are creating the power to spread good and bad. Time and time again, people have managed to guide innovations for the good of humanity. In some ways, AIs remind me of nuclear technologies. Handled poorly, they could destroy the world. But they haven’t. In fact, we have avoided another world war thanks in part to mutual assured destruction, and atomic know-how has quietly revolutionized healthcare, energy, robotics, physics and aerospace.Yes, the extremes are scary, but they are only part of the story. If we are to harness AIs for universal good, we need to be more realistic about their daily implications and the net benefits thereof. Less “duck and cover” and more comprehensive conversation.

But AIs are not just for the big guys. Why? Three reasons. First, the affordability of massive computing power. Indeed, the commoditization of compute power is a large part of why the big cloud platforms want you developing models on top of Azure, AWS, Watson and GCP, and why Intel and NVIDIA want you doing it on their silicon. Second, there are more ML- andAI-trained engineersthan ever before, taking advantage of decades of science advancing the underlying algorithms.

Third, largely behind the scenes, product teams from startups to retailers and systems integrators are applying others’AIplatforms using their own proprietary training data. The most sophisticated algorithms are only able to see, listen, talk and “think” like humans if the right humans are training and re-training them as our fickle human opinions evolve. Nobody understands shoes like Shoes.com, surfing videos like GoPro, top-shelf stock imagery like Getty — and their customers.

Sometimes the ability to leverage cognitive computing is less about the underlying algorithms and more about how they are tuned and productized. Mark my words: It’s not just who has the models, it’s about who applies the right data.

Lastly, can we please stop evaluating AIs based on whether they are saving us from cancer or threatening humanity? These questions bait valuable conversations, but miss the bigger, more important “middle.” I love telling my mom that we train AIs. But AIs are not the goal. When we all go to that tech-loving part of our brain, we forget that AIs are themeansto improved experiences.

We all accept that a picture is “worth a thousand words.” We also know that most of our communication is non-verbal (just contrast your last date, or in-person interview, with your last telecon call). So how much are 100 million images worth? How about terabytes of CT scans of your loved one’s brain tumor? And what about 24 hours of video, at 30 fps? Well, of course, that depends on what’s in the data — and, more importantly, what we can do with it.AIs hold the key to unlocking the value buried in the massive, exponentially growing sets of unstructured content with which we each interact daily.As such, I humbly propose that we measure the value of anAIbased on its ability to contribute positive utility to people. We all know that at the end of the day, it’s the people who matter in our lives. Just the same, we need to remember that AIs should be measured by their ability to understand, interact with and improve people’s lives. This utilitarian framework offers hundreds of years of insights from philosophers, economists and anthropologists.The new nukesAIs are pervasive, and are creating the power to spread good and bad. Time and time again, people have managed to guide innovations for the good of humanity. In some ways, AIs remind me of nuclear technologies. Handled poorly, they could destroy the world. But they haven’t. In fact, we have avoided another world war thanks in part to mutual assured destruction, and atomic know-how has quietly revolutionized healthcare, energy, robotics, physics and aerospace.Yes, the extremes are scary, but they are only part of the story. If we are to harness AIs for universal good, we need to be more realistic about their daily implications and the net benefits thereof. Less “duck and cover” and more comprehensive conversation.

We all accept that a picture is “worth a thousand words.” We also know that most of our communication is non-verbal (just contrast your last date, or in-person interview, with your last telecon call). So how much are 100 million images worth? How about terabytes of CT scans of your loved one’s brain tumor? And what about 24 hours of video, at 30 fps? Well, of course, that depends on what’s in the data — and, more importantly, what we can do with it.

AIs hold the key to unlocking the value buried in the massive, exponentially growing sets of unstructured content with which we each interact daily.

As such, I humbly propose that we measure the value of anAIbased on its ability to contribute positive utility to people. We all know that at the end of the day, it’s the people who matter in our lives. Just the same, we need to remember that AIs should be measured by their ability to understand, interact with and improve people’s lives. This utilitarian framework offers hundreds of years of insights from philosophers, economists and anthropologists.

AIs are pervasive, and are creating the power to spread good and bad. Time and time again, people have managed to guide innovations for the good of humanity. In some ways, AIs remind me of nuclear technologies. Handled poorly, they could destroy the world. But they haven’t. In fact, we have avoided another world war thanks in part to mutual assured destruction, and atomic know-how has quietly revolutionized healthcare, energy, robotics, physics and aerospace.

Yes, the extremes are scary, but they are only part of the story. If we are to harness AIs for universal good, we need to be more realistic about their daily implications and the net benefits thereof. Less “duck and cover” and more comprehensive conversation.